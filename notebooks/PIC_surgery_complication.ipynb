{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fleet-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import featuretools as ft\n",
    "from featuretools.selection import remove_low_information_features, \\\n",
    "    remove_highly_correlated_features, remove_highly_null_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "martial-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = os.path.abspath('../')\n",
    "# PIC_dir = os.path.join(ROOT, 'data/raw/PIC/')\n",
    "PIC_dir = os.path.join(ROOT, 'data/raw/PIC_mini/')\n",
    "output_dir = os.path.join(ROOT, 'data/intermediate/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-knight",
   "metadata": {},
   "source": [
    "## 1. Entityset Generation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imperial-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_entityset(entityset):  # saves a serialized entity set in output_dir/entityset\n",
    "    with open(os.path.join(output_dir, 'entityset'), 'wb') as f:\n",
    "        pickle.dump(entityset, f)\n",
    "        \n",
    "def load_entityset(): # loads a serialized entiy set\n",
    "    with open(os.path.join(output_dir, 'entityset'), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_fm(df, fm_list, token=''):  # saves a fm_list both as a pickle and a csv\n",
    "    if str(token) != '':\n",
    "        token = '_' + str(token)\n",
    "    with open(os.path.join(output_dir, 'fl{}.pkl'.format(token)), 'wb') as f:\n",
    "        pickle.dump(fm_list, f)\n",
    "    df.to_csv(os.path.join(output_dir, 'fm{}.csv'.format(token)))\n",
    "    \n",
    "def load_fm(token=None): # loads an fm_list both as an object and a DataFrame\n",
    "    if str(token) != '':\n",
    "        token = '_' + str(token)\n",
    "    with open(os.path.join(output_dir, 'fl{}.pkl'.format(token)), 'rb') as f:\n",
    "        fm_list = pickle.load(f)\n",
    "    df = pd.read_csv(os.path.join(output_dir, 'fm{}.pkl'.format(token)), index_col=0)\n",
    "    return df, fm_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continent-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIONSHIPS = [\n",
    "    # PATIENTS\n",
    "    ('PATIENTS', 'SUBJECT_ID', 'ADMISSIONS', 'SUBJECT_ID'),\n",
    "    ('PATIENTS', 'SUBJECT_ID', 'PRESCRIPTIONS', 'SUBJECT_ID'),\n",
    "    # ADMISSIONS\n",
    "    ('ADMISSIONS', 'HADM_ID', 'ICUSTAYS', 'HADM_ID'),\n",
    "    ('ADMISSIONS', 'HADM_ID', 'DIAGNOSES_ICD', 'HADM_ID'),\n",
    "    ('ADMISSIONS', 'HADM_ID', 'EMR_SYMPTOMS', 'HADM_ID'),\n",
    "    ('ADMISSIONS', 'HADM_ID', 'LABEVENTS', 'HADM_ID'),\n",
    "    ('ADMISSIONS', 'HADM_ID', 'MICROBIOLOGYEVENTS', 'HADM_ID'),\n",
    "    ('ADMISSIONS', 'HADM_ID', 'OR_EXAM_REPORTS', 'HADM_ID'),\n",
    "    ('ADMISSIONS', 'HADM_ID', 'SURGERY_INFO', 'HADM_ID'),\n",
    "    ('ADMISSIONS', 'HADM_ID', 'CHARTEVENTS', 'HADM_ID'),\n",
    "    ('ADMISSIONS', 'HADM_ID', 'OUTPUTEVENTS', 'HADM_ID'),\n",
    "    ('ADMISSIONS', 'HADM_ID', 'PRESCRIPTIONS', 'HADM_ID'),\n",
    "    # SURGERYS\n",
    "    ('SURGERY_INFO', 'UNI_OPER_ID', 'SURGERY_VITAL_SIGNS', 'UNI_OPER_ID'),\n",
    "    # ICUSTAYS\n",
    "    ('ICUSTAYS', 'ICUSTAY_ID', 'INPUTEVENTS', 'ICUSTAY_ID'),\n",
    "#     ('ICUSTAYS', 'ICUSTAY_ID', 'CHARTEVENTS', 'ICUSTAY_ID'),\n",
    "#     ('ICUSTAYS', 'ICUSTAY_ID', 'OUTPUTEVENTS', 'ICUSTAY_ID'),\n",
    "#     ('ICUSTAYS', 'ICUSTAY_ID', 'PRESCRIPTIONS', 'ICUSTAY_ID'),\n",
    "    # DICTS\n",
    "    ('D_ITEMS', 'ITEMID', 'CHARTEVENTS', 'ITEMID'),\n",
    "    ('D_ITEMS', 'ITEMID', 'OUTPUTEVENTS', 'ITEMID'),\n",
    "    ('D_ITEMS', 'ITEMID', 'MICROBIOLOGYEVENTS', 'SPEC_ITEMID'),\n",
    "    ('D_ITEMS', 'ITEMID', 'MICROBIOLOGYEVENTS', 'ORG_ITEMID'),\n",
    "    ('D_ITEMS', 'ITEMID', 'MICROBIOLOGYEVENTS', 'AB_ITEMID'),\n",
    "    ('D_ITEMS', 'ITEMID', 'SURGERY_VITAL_SIGNS', 'ITEMID'),\n",
    "    ('D_LABITEMS', 'ITEMID', 'LABEVENTS', 'ITEMID'),\n",
    "    ('D_ICD_DIAGNOSES', 'ICD10_CODE_CN', 'DIAGNOSES_ICD', 'ICD10_CODE_CN'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "egyptian-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "META_INFO = {\n",
    "    'PATIENTS': {\n",
    "        'index': 'SUBJECT_ID',\n",
    "        'types': {'SUBJECT_ID': 'int', 'EXPIRE_FLAG': 'bool'},\n",
    "#         'secondary_index': {\n",
    "#             'DOB': ['EXPIRE_FLAG'],\n",
    "#             'DOD': ['EXPIRE_FLAG'],\n",
    "#         }\n",
    "    },\n",
    "    'ADMISSIONS': {\n",
    "        'index': 'HADM_ID',\n",
    "        'foreign_index': ['SUBJECT_ID'],\n",
    "        'types': {'SUBJECT_ID': 'int', 'HADM_ID': 'int'},\n",
    "        'time_index': 'ADMITTIME',\n",
    "        'secondary_index': {\n",
    "            'DISCHTIME': ['DISCHARGE_DEPARTMENT', 'HOSPITAL_EXPIRE_FLAG', 'DIAGNOSIS', 'EDOUTTIME'],\n",
    "            'DEATHTIME': ['DISCHARGE_DEPARTMENT', 'HOSPITAL_EXPIRE_FLAG', 'DIAGNOSIS', 'EDOUTTIME'],\n",
    "        },\n",
    "    },\n",
    "    'ICUSTAYS': {\n",
    "        'index': 'ICUSTAY_ID',\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID'],\n",
    "        'types': {'HADM_ID': 'int', 'ICUSTAY_ID': 'int', 'FIRST_WARDID': 'str', \n",
    "                  'LAST_WARDID': 'str'},\n",
    "        'time_index': 'INTIME',\n",
    "        'secondary_index': {\n",
    "            'OUTTIME': ['LAST_CAREUNIT', 'LAST_WARDID', 'LOS']\n",
    "        }\n",
    "    },\n",
    "    'SURGERY_INFO': {\n",
    "        'index': 'UNI_OPER_ID',\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID'],\n",
    "        'types': {'HADM_ID': 'int', 'VISIT_ID': 'str', 'OPER_ID': 'str'},\n",
    "        'time_index': 'ANES_START_TIME',\n",
    "        'secondary_index': {\n",
    "            'ANES_END_TIME': [],\n",
    "            'SURGERY_BEGIN_TIME': [],\n",
    "            'SURGERY_END_TIME': []\n",
    "        }\n",
    "    },\n",
    "    'DIAGNOSES_ICD': {\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID', 'ICD10_CODE_CN'],\n",
    "        'types': {'ICD10_CODE_CN': 'str', 'HADM_ID': 'int'},\n",
    "    },\n",
    "    'SURGERY_VITAL_SIGNS': {\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID', 'ITEMID', 'OPER_ID'],\n",
    "        'types': {'HADM_ID': 'int', 'ITEMID': 'str', 'VISIT_ID': 'int', \n",
    "                  'OPER_ID': 'int', 'ITEM_NO': 'int'},\n",
    "        'time_index': 'MONITOR_TIME',\n",
    "    },\n",
    "    'EMR_SYMPTOMS': {\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID', 'EMR_ID'],\n",
    "        'types': {'HADM_ID': 'int'},\n",
    "        'time_index': 'RECORDTIME',\n",
    "    },\n",
    "    'LABEVENTS': {\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID', 'ITEMID'],\n",
    "        'types': {'HADM_ID': 'int', 'ITEMID': 'str'},\n",
    "        'time_index': 'CHARTTIME'\n",
    "    },\n",
    "    'MICROBIOLOGYEVENTS': {\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID', 'SPEC_ITEMID', 'ORG_ITEMID', 'AB_ITEMID'],\n",
    "        'types': {'HADM_ID': 'int', 'SPEC_ITEMID': 'str', \n",
    "                  'ORG_ITEMID': 'str', 'AB_ITEMID': 'str'},\n",
    "        'time_index': 'CHARTTIME'\n",
    "    },\n",
    "    'OR_EXAM_REPORTS': {\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID'],\n",
    "        'types': {'HADM_ID': 'int'},\n",
    "        'time_index': 'REPORTTIME'\n",
    "    },\n",
    "    'CHARTEVENTS': {\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID', 'ITEMID'],\n",
    "        'types': {'ITEMID': 'str'},\n",
    "        'time_index': 'CHARTTIME'\n",
    "    },\n",
    "    'INPUTEVENTS': {\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID'],\n",
    "        'types': {'ICUSTAY_ID': 'int'},\n",
    "        'time_index': 'CHARTTIME'\n",
    "    },\n",
    "    'OUTPUTEVENTS': {\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID', 'ITEMID'],\n",
    "        'types': {'ITEMID': 'str'},\n",
    "        'time_index': 'CHARTTIME'\n",
    "    },\n",
    "    'PRESCRIPTIONS': {\n",
    "        'foreign_index': ['SUBJECT_ID', 'HADM_ID'],\n",
    "        'time_index': 'STARTDATE',\n",
    "        'secondary_index': {\n",
    "            'ENDDATE': []\n",
    "        }\n",
    "    },\n",
    "    'D_ITEMS': {\n",
    "        'index': 'ITEMID',\n",
    "        'types': {'ITEMID': 'str'},\n",
    "    },\n",
    "    'D_LABITEMS': {\n",
    "        'index': 'ITEMID',\n",
    "        'types': {'ITEMID': 'str'},\n",
    "    },\n",
    "    'D_ICD_DIAGNOSES': {\n",
    "        'index': 'ICD10_CODE_CN',\n",
    "        'types': {'ICD10_CODE_CN': 'str'},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "detailed-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_entries(df, key_columns, verbose=True):\n",
    "    n_row = len(df)\n",
    "    for column in key_columns:\n",
    "        df = df[df[column] == df[column]]\n",
    "    if verbose:\n",
    "        print(\"Prune ({}/{}) rows.\".format(n_row-len(df), n_row))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hairy-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pic(save=True):\n",
    "    \n",
    "    es = ft.EntitySet(id=\"pic\")\n",
    "\n",
    "    for table_name, info in META_INFO.items(): # Iterate through entries in the META_INFO defined above, which includes tables names and various index types\n",
    "\n",
    "        table_df = pd.read_csv(os.path.join(PIC_dir, '{}.csv'.format(table_name)),\n",
    "                               date_parser=pd.to_datetime)\n",
    "        \n",
    "        if table_name in ['SURGERY_INFO', 'SURGERY_VITAL_SIGNS']:\n",
    "            table_df['UNI_OPER_ID'] = (table_df['HADM_ID'] - 100000)*64 + table_df['VISIT_ID']*8 + table_df['OPER_ID']\n",
    "            \n",
    "        if table_name == 'SURGERY_INFO':\n",
    "            table_df = table_df[~table_df['UNI_OPER_ID'].duplicated()]\n",
    "\n",
    "        index = info.get('index', 'ROW_ID')\n",
    "        index_columns = info.get('foreign_index', [])+[index]\n",
    "        table_df = remove_nan_entries(table_df, index_columns)\n",
    "\n",
    "        for col, t in info.get('types', {}).items():\n",
    "            table_df[col] = table_df[col].astype(t)\n",
    "\n",
    "        es.entity_from_dataframe(entity_id=table_name,\n",
    "                                 dataframe=table_df,\n",
    "                                 index=index,\n",
    "                                 time_index=info.get('time_index', None),\n",
    "                                 secondary_time_index=info.get('secondary_index', None))\n",
    "    \n",
    "    for parent, primary_key, child, foreign_key in RELATIONSHIPS:\n",
    "        new_relationship = ft.Relationship(es[parent][primary_key], es[child][foreign_key])\n",
    "\n",
    "        es = es.add_relationship(new_relationship)\n",
    "        \n",
    "    if save:\n",
    "        save_entityset(es)\n",
    "        \n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alone-raising",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prune (0/1934) rows.\n",
      "Prune (0/1996) rows.\n",
      "Prune (0/2108) rows.\n",
      "Prune (0/1975) rows.\n",
      "Prune (0/3778) rows.\n",
      "Prune (0/754213) rows.\n",
      "Prune (0/75981) rows.\n",
      "Prune (0/1724805) rows.\n",
      "Prune (12106/29547) rows.\n",
      "Prune (0/39872) rows.\n",
      "Prune (0/450989) rows.\n",
      "Prune (253/2837) rows.\n",
      "Prune (0/7849) rows.\n",
      "Prune (0/171332) rows.\n",
      "Prune (0/479) rows.\n",
      "Prune (0/832) rows.\n",
      "Prune (0/25379) rows.\n"
     ]
    }
   ],
   "source": [
    "es = load_pic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-milan",
   "metadata": {},
   "source": [
    "## 2. Feature Generation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "derived-chassis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "es = load_entityset()\n",
    "\n",
    "# 19 distinct items in total\n",
    "chart_event_items = es['CHARTEVENTS'].df['ITEMID'].unique()\n",
    "\n",
    "# select frequent lab test items, 18 among 821\n",
    "lab_count = es['LABEVENTS'].df['ITEMID'].value_counts()\n",
    "lab_test_items = lab_count[lab_count > 40000].index\n",
    "\n",
    "# 6 distinct items in total\n",
    "vital_sign_items = es['SURGERY_VITAL_SIGNS'].df['ITEMID'].unique()\n",
    "\n",
    "# select 25 frequent symptoms, \n",
    "emr_count = es['EMR_SYMPTOMS'].df['SYMPTOM_NAME'].value_counts()\n",
    "emr_items = emr_count[emr_count > 800].index\n",
    "\n",
    "# select 26 frequent prescriptions\n",
    "prescription_items = es[\"PRESCRIPTIONS\"].df['DRUG_NAME_EN'].value_counts()\n",
    "prescription_items = prescription_items[prescription_items > 1500]\n",
    "\n",
    "es['CHARTEVENTS']['ITEMID'].interesting_values = chart_event_items\n",
    "es['LABEVENTS']['ITEMID'].interesting_values = lab_test_items\n",
    "es['SURGERY_VITAL_SIGNS']['ITEMID'].interesting_values = vital_sign_items\n",
    "es['EMR_SYMPTOMS']['SYMPTOM_NAME'].interesting_values = emr_items\n",
    "es['PRESCRIPTIONS']['DRUG_NAME_EN'].interesting_values = prescription_items\n",
    "\n",
    "# add last time indexes\n",
    "es.add_last_time_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conscious-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_variables = {\n",
    "    'PATIENTS': ['ROW_ID', 'EXPIRE_FLAG', 'DOD', 'SUBJECT_ID'],\n",
    "    'ADMISSIONS': ['ROW_ID', 'HADM_ID', 'SUBJECT_ID'],\n",
    "    'ICUSTAYS': ['ROW_ID', 'HADM_ID', 'ICUSTAY_ID', 'SUBJECT_ID'],\n",
    "    'SURGERY_INFO': ['ROW_ID', 'HADM_ID', 'SUBJECT_ID', 'VISIT_ID', 'OPER_ID'],\n",
    "    'DIAGNOSES_ICD': ['ROW_ID', 'HADM_ID', 'SUBJECT_ID'],\n",
    "    'SURGERY_VITAL_SIGNS': ['ROW_ID', 'HADM_ID', 'SUBJECT_ID', 'VISIT_ID', 'OPER_ID', 'ITEM_NO'],\n",
    "    'EMR_SYMPTOMS': ['ROW_ID', 'HADM_ID', 'SUBJECT_ID', 'EMR_ID', 'SYMPTOM_NAME_CN'],\n",
    "    'LABEVENTS': ['ROW_ID', 'HADM_ID', 'SUBJECT_ID', 'VALUEUOM', 'CHARTTIME'],\n",
    "    'MICROBIOLOGYEVENTS': ['ROW_ID', 'HADM_ID', 'SUBJECT_ID', 'AB_ITEMID', 'ORG_ITEMID', 'SPEC_ITEMID'],\n",
    "    'OR_EXAM_REPORTS': ['ROW_ID', 'HADM_ID', 'SUBJECT_ID', 'REPORTTIME'],\n",
    "    'CHARTEVENTS': ['ROW_ID', 'SUBJECT_ID', 'HADM_ID', 'ICUSTAY_ID', 'VALUEUOM', 'STORETIME'],\n",
    "    'INPUTEVENTS': ['ROW_ID', 'HADM_ID', 'ICUSTAY_ID', 'SUBJECT_ID'],\n",
    "    'OUTPUTEVENTS': ['ROW_ID', 'HADM_ID', 'ICUSTAY_ID', 'ITEMID', 'SUBJECT_ID'],\n",
    "    'PRESCRIPTIONS': ['ROW_ID', 'HADM_ID', 'ICUSTAY_ID', 'SUBJECT_ID', 'DOSE_UNIT_RX', 'PROD_STRENGTH', \n",
    "                      'DRUG_NAME_GENERIC', 'DOSE_UNIT_RX', 'DRUG_FORM', 'DRUG_NAME'],\n",
    "    'D_ITEMS': ['ROW_ID', 'ITEMID', 'UNITNAME', 'LINKSTO', 'LABEL_CN', 'CATEGORY'],\n",
    "    'D_LABITEMS': ['ROW_ID', 'ITEMID', 'LABEL_CN'],\n",
    "    'D_ICD_DIAGNOSES': ['ROW_ID']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "palestinian-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(fm, fl=None):\n",
    "    fm = remove_highly_null_features(fm)\n",
    "    fm = remove_low_information_features(fm)\n",
    "#     fm = remove_highly_correlated_features(fm)\n",
    "    if fl is None:\n",
    "        return fm\n",
    "    else:\n",
    "        fl = [f for f in fl if f._name in fm.columns]\n",
    "        return fm, fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-fabric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 65 features\n",
      "Elapsed: 00:40 | Progress:  10%|â–ˆ         "
     ]
    }
   ],
   "source": [
    "# Define pc problem\n",
    "target_entity = 'SURGERY_INFO'\n",
    "label_times = es['SURGERY_INFO'].df[['UNI_OPER_ID', 'SURGERY_END_TIME']]\n",
    "label_times.columns = ['instance_id', 'time']\n",
    "\n",
    "# Generate features\n",
    "feature_matrix, features_list = ft.dfs(entityset=es,\n",
    "                                       target_entity=target_entity,\n",
    "                                       agg_primitives=[\"std\", \"mean\", \"trend\"],\n",
    "                                       where_primitives=[\"mean\", \"std\", \"trend\"],\n",
    "                                       trans_primitives=[],\n",
    "                                       allowed_paths=[['SURGERY_INFO', 'SURGERY_VITAL_SIGNS']],\n",
    "                                       ignore_variables=ignore_variables,\n",
    "                                       cutoff_time=label_times,\n",
    "                                       max_depth=2,\n",
    "                                       verbose=True)\n",
    "\n",
    "feature_matrix, features_list = select_features(feature_matrix, features_list)\n",
    "save_fm(feature_matrix, features_list, 'signal_only_raw')\n",
    "\n",
    "# One-hot encoding\n",
    "feature_matrix, features_list = ft.encode_features(feature_matrix, features_list, top_n=10)\n",
    "save_fm(feature_matrix, features_list, 'signal_only')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-civilian",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-plumbing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "add_info = pd.read_csv(os.path.join(PIC_dir, 'surgery_additional_features.csv'), index_col=0)\n",
    "partial_merged_fm = pd.merge(feature_matrix, add_info, left_index=True, right_index=True)\n",
    "partial_merged_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#def maximum(column):\n",
    "#    results = [x in ]\n",
    "\n",
    "def exists(column, values=None):\n",
    "    assert values is not None\n",
    "    return [v in column.values for v in values]\n",
    "\n",
    "\n",
    "Medications = ft.primitives.make_agg_primitive(function=exists,\n",
    "                                 input_types=[ft.variable_types.Discrete],\n",
    "                                 return_type=ft.variable_types.Boolean,\n",
    "                                 number_output_features=len(prescription_items))\n",
    "    \n",
    "med_feature_matrix, med_features_list = ft.dfs(entityset=es,\n",
    "                                       target_entity=target_entity,\n",
    "                                       agg_primitives=[Medications(values=prescription_items.index)],\n",
    "                                       allowed_paths=[['SURGERY_INFO', 'ADMISSIONS'],  \n",
    "                                                      ['SURGERY_INFO', 'ADMISSIONS', 'PRESCRIPTIONS']],\n",
    "                                       ignore_variables=ignore_variables,\n",
    "                                       cutoff_time=label_times,\n",
    "                                       max_depth=2,\n",
    "                                       verbose=True)\n",
    "\n",
    "med_feature_matrix = med_feature_matrix.fillna(0)\n",
    "\n",
    "med_feature_matrix, med_features_list = select_features(feature_matrix, features_list)\n",
    "#save_fm(feature_matrix, features_list, 'signal_only_raw')\n",
    "\n",
    "# One-hot encoding\n",
    "med_feature_matrix, med_features_list = ft.encode_features(feature_matrix, features_list, top_n=10)\n",
    "#save_fm(feature_matrix, features_list, 'signal_only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fm = pd.merge(partial_merged_fm, feature_matrix, left_index=True, right_index=True)\n",
    "merged_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "for label_name in ['complication', 'lung complication', 'cardiac complication', \n",
    "        'arrhythmia complication', 'infectious complication', 'other complication']:\n",
    "    labels[label_name] = merged_fm.pop(label_name)\n",
    "X = merged_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "y = labels['cardiac complication']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "train_index = X_train.index\n",
    "test_index = X_test.index\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "model = XGBClassifier()\n",
    "\n",
    "classification_metrics = {\n",
    "    'Accuracy': sklearn.metrics.accuracy_score,\n",
    "    'F1 Macro': lambda y_true, y_pred: sklearn.metrics.f1_score(y_true, y_pred, average=\"macro\"),\n",
    "    'Precision': lambda y_true, y_pred: sklearn.metrics.precision_score(y_true, y_pred, average=\"macro\"),\n",
    "    'Recall': lambda y_true, y_pred: sklearn.metrics.recall_score(y_true, y_pred, average=\"macro\"),\n",
    "    'Confusion Matrix': sklearn.metrics.confusion_matrix,\n",
    "    'AUROC': lambda y_true, y_pred: sklearn.metrics.roc_auc_score(y_true, y_pred, average=\"macro\"),\n",
    "}\n",
    "\n",
    "def test(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    scores = {}\n",
    "    for name, func in classification_metrics.items():\n",
    "        scores[name] = func(y, y_pred)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imputer.fit_transform(X_train)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = imputer.transform(X_test)\n",
    "X_test_copy = X_test.copy()\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "weights = class_weight.compute_class_weight('balanced', y_train.unique(), y_train)\n",
    "sample_weight = [weights[l] for l in y_train]\n",
    "\n",
    "model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "test(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-graham",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-australian",
   "metadata": {},
   "source": [
    "## 4. Model Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values_train = explainer.shap_values(X_train)\n",
    "shap_values_test = explainer.shap_values(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values_train, pd.DataFrame(X_train, columns=X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for signal explanations\n",
    "\n",
    "def visualize_signal(signal, c=None, vmin=None, vmax=None):\n",
    "    plt.plot(np.arange(len(signal)), signal, c=\"black\", zorder=1)\n",
    "    plt.scatter(np.arange(len(signal)), signal, c=c, cmap=\"Reds_r\", vmin=vmin, vmax=vmax, zorder=2)\n",
    "    if c is not None:\n",
    "        plt.colorbar()\n",
    "        \n",
    "def distribute_shap(shap_values, v):\n",
    "    v_norm = v / sum(v)\n",
    "    return shap_values * v_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to run occlusion algorithm\n",
    "\n",
    "def occlude(signal, algorithm, start, size):\n",
    "    # algorithm - one of:\n",
    "    #    linear - linearly connect the window endpoints\n",
    "    #    mean - fill with constant equal to window mean\n",
    "    #    start - fill with constant equal to first endpoint\n",
    "    #    mean_endpoints - fill with constant equal to mean of endpoints\n",
    "    \n",
    "    occluded = signal.copy()\n",
    "    endpoint_1 = signal[start]\n",
    "    if start+size-1 < len(signal):\n",
    "        endpoint_2 =signal[start+size-1]\n",
    "    else:\n",
    "        endpoint_2 = signal[len(signal)-1]\n",
    "        \n",
    "    if algorithm == \"linear\":\n",
    "        occluded[start:start+size] = np.linspace(endpoint_1, endpoint_2, len(occluded[start:start+size]))\n",
    "        return occluded\n",
    "            \n",
    "    if algorithm == \"mean\":\n",
    "        value = signal[start:start+size].mean()\n",
    "        \n",
    "    if algorithm == \"start\":\n",
    "        value = signal[start]\n",
    "        \n",
    "    if algorithm == \"mean_endpoints\":\n",
    "        value = (endpoint_1 + endpoint_2) / 2\n",
    "    \n",
    "    occluded[start:start+size] = value\n",
    "    return occluded\n",
    "\n",
    "def run_occlusion(signal, feature_algos, algorithm, window_size=10):\n",
    "    base_values = []\n",
    "    for algo in feature_algos:\n",
    "        base_values.append(algo(signal))\n",
    "    v = np.zeros((len(signal), len(feature_algos)))\n",
    "    hits = np.zeros(len(signal))\n",
    "    for start in range(len(signal)):\n",
    "        occluded = occlude(signal, \"linear\", start, window_size)\n",
    "        new_values = []\n",
    "        for algo in feature_algos:\n",
    "            new_values.append(algo(occluded))\n",
    "        for i in range(len(base_values)):\n",
    "            v[start:start+window_size, i] += ((base_values[i] - new_values[i]) / np.abs(base_values[i])) \n",
    "        hits[start:start+window_size] += 1\n",
    "\n",
    "    v = v / hits.reshape(-1, 1)\n",
    "    return v\n",
    "\n",
    "def mean_contributions(signal):\n",
    "    # Calculate the importance of each point to the mean\n",
    "    mean = np.mean(signal)\n",
    "    n = len(signal)\n",
    "    new_means = np.array([(np.sum(signal) - x + mean) / n for x in signal])\n",
    "    v = (mean - new_means) / (np.abs(mean))\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for selecting which surgery/feature to explain\n",
    "\n",
    "UNI_OPER_ID = 885705  # surgery ID of interest\n",
    "FEATURE_NAME = \"Pulse\"\n",
    "FEATURE_TABLE = \"SURGERY_VITAL_SIGNS\"\n",
    "\n",
    "FEATURE_EXTRACTION_ALGOS = [np.mean, np.std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT THE SIGNAL OF INTEREST\n",
    "\n",
    "feature_rows = es[\"D_ITEMS\"].df.loc[es[\"D_ITEMS\"].df[\"LABEL\"] == FEATURE_NAME]\n",
    "feature_code = feature_rows.loc[feature_rows[\"LINKSTO\"].str.lower() == FEATURE_TABLE.lower()][\"ITEMID\"][0]\n",
    "\n",
    "feature_table = es[FEATURE_TABLE].df\n",
    "uni_oper_id_feature_table = feature_table.loc[feature_table[\"UNI_OPER_ID\"] == UNI_OPER_ID]\n",
    "\n",
    "feature_measures = uni_oper_id_feature_table.loc[uni_oper_id_feature_table[\"ITEMID\"] == feature_code]\n",
    "feature_measures.sort_values(by=\"MONITOR_TIME\", axis=\"index\", inplace=True)\n",
    "\n",
    "feature_signal = feature_measures[\"VALUE\"]\n",
    "\n",
    "visualize_signal(feature_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature extraction importances of each signal point\n",
    "\n",
    "v = run_occlusion(feature_signal.to_numpy(), FEATURE_EXTRACTION_ALGOS, \"linear\")\n",
    "#v_mean = mean_contributions(feature_signal.to_numpy())\n",
    "\n",
    "visualize_signal(feature_signal, c=v[:,0])\n",
    "plt.title(\"Mean\")\n",
    "plt.show()\n",
    "\n",
    "#visualize_signal(feature_signal, c=v[:,1], vmin=-.2, vmax=.2)\n",
    "#plt.title(\"Std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the relevant shap values\n",
    "\n",
    "SHAP_BASE_NAME = \"(SURGERY_VITAL_SIGNS.VALUE WHERE ITEMID = %s)_x\" % feature_code\n",
    "SHAP_ALGO_NAMES = [\"MEAN\", \"STD\"]\n",
    "\n",
    "feature_inds = [X.columns.get_loc(name + SHAP_BASE_NAME) for name in SHAP_ALGO_NAMES]\n",
    "\n",
    "row_ind = np.where(train_index == UNI_OPER_ID)[0]\n",
    "if len(row_ind) > 0:\n",
    "    surgery_feature_shap_values = shap_values_train[:, feature_inds][row_ind[0]]\n",
    "else:\n",
    "    row_ind = np.where(test_index == UNI_OPER_ID)[0]\n",
    "    surgery_feature_shap_values = shap_values_test[:, feature_inds][row_ind[0]]\n",
    "    \n",
    "weighted_shap = distribute_shap(surgery_feature_shap_values, np.abs(v))\n",
    "\n",
    "visualize_signal(feature_signal, c=weighted_shap[:,0] + weighted_shap[:,1], vmin=-.03, vmax=0)\n",
    "plt.title(\"Pulse Contribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-vienna",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pic-venv",
   "language": "python",
   "name": "pic-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
